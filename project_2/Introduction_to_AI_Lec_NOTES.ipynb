{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Navigation\n",
    "\n",
    "- comutational hard\n",
    "- finding shortest path between two location\n",
    "- breath first search? (not very efficient)\n",
    "\n",
    "#### How to find the shortest path between two locations\n",
    "Only consider roadways going in you end destination.\n",
    "\n",
    "Heuristic: some aditional piece of information, a rule, function or constrain that informs an otherwise brute-force algorithmn to act in a more optimal manner.\n",
    "\n",
    "The actual shortest path between two cities is an actual direct line \"as the crow flies\".\n",
    "If you take a radom step in any direction, the new direct distance to destination has changed, in this case it has increase.\n",
    "\n",
    "You test all possible next step from current position to see which one has the lowest distance, then choose that one.\n",
    "\n",
    "Now, the current next step seems like the best choice may not turn out to be on the optimal path.\n",
    "\n",
    "We are only using our direct distance **heuristic** to decide which step to explore next.\n",
    "**forshadowing..!**  A*search\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Game Playing\n",
    "\n",
    "Question: Is optimising really AI?\n",
    "\n",
    "An intelligent should be able to react to changes in the enviroment and dare say  `[blazin_saddles.gif]`... antisipate them..\n",
    "\n",
    "## QUIZ: Tic Tac Toe\n",
    "\n",
    "**Goal**: USe a search strategy similar to the route-finding problem, to design and AI that can play Tic Tac Toe.\n",
    "\n",
    "- A: shoue each cell be a separate node, with an edge connecting two of them if they are adjacent?\n",
    "- B: Use the current position of the computer player as a node, expressed as a*row/col* tuple where row, column are *{0,1,2}*.\n",
    "    - Two nodes can ve connected if thery row and col values differ by at most one, e.g(0,1) shoudl be connected to (1,0) but not (2,2)\n",
    "- C: keep track of the opponent's current position as well. So each node will be a pair of tuples  such as <(0,1),(2,0)>. For edges, we can use the same rule - connect if the computers player's positions differ by at most one.\n",
    "- D: Think of th whole board as a node, so we'll have one onode for every possible arrangement of X's and O's on the board. In this case, connected two nodes if there is a valid move that changes the board from one to the other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tic Tac Toe: Heuristics\n",
    "\n",
    "You are limited by the number of moves you might need to consider, especially later int ehgame when the board is more full.\n",
    "\n",
    "Example:\n",
    "- on a 3x3 board, the very first move has 9 diffrent posibilities, and 8 for the oponent, and so on..\n",
    "- But some moves are clearly a wastefull moves,\n",
    "\n",
    "### Pruning the search tree\n",
    "- When you have a move position that will never contribute ot a winning combination.\n",
    "- Being able to ignore moves based on easy to evaluate conditions\n",
    "- Know that you are going against someone who is also trying to win.\n",
    "\n",
    "#### Mini-Max Algorithm\n",
    "You are trying to *maximize* your chances of winning on your turn, and  your opponents is trying to *minimize* your chance of winnign on their turn.\n",
    "\n",
    "A better definition of an Intelligen Agent: Anticipate and plan around expected changes in its enviroment including those introduced by other agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Monty Hall  Explained.\n",
    "\n",
    "You are show 3 doors...\n",
    "```$\n",
    "+----------+     +----------+     +----------+\n",
    "|          |     |          |     |          |\n",
    "|          |     |          |     |          |\n",
    "|   DOOR   |     |   DOOR   |     |   DOOR   |\n",
    "|    A     |     |    B     |     |    C     |\n",
    "|        0 |     |        0 |     |        0 |\n",
    "|          |     |          |     |          |\n",
    "|          |     |          |     |          |\n",
    "|          |     |          |     |          |\n",
    "+----------+     +----------+     +----------+\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "$P(Car_A) + P(Car_B) + P(Car_C) = 1$\n",
    "\n",
    "Because we have 3 doors we can say that each door has a probability of 1/3 or..\n",
    "\n",
    "**Prior Probability**: BEst guess given no further evidence.\n",
    "$$\n",
    "P(Car_A)= \\frac{1}{3},  P(Car_B) \\frac{1}{3}, P(Car_C) =  \\frac{1}{3}\n",
    "$$\n",
    "\n",
    "Let Choose Door A as our first choice, then Monty opens one of the other two doors, say **B**, to reveal a goat, which cleary implies that door **B** does not have the car.\n",
    "That leads to $Open_B$ Observation:$P(Car_B | Open_B)=0$ is known as the *posterior probability*: our belief after incorporating an observation.\n",
    "\n",
    "Now Because we have two doors that are closed. You think now tha the probability of each door should be 1/2 but it is not.\n",
    "\n",
    "We need to find the *posterior probabily* of the car being behind door **C**, given Monty opend door **B** and the implicid rule that he would never reveal the car. $P(Car_C | Open_B)=?$\n",
    "\n",
    "We can rewrite this *posterior probability* in terms of other wquantities that we can computer usign *Bayes' Theorem*\n",
    "$$\n",
    "= \\frac{(P(Open_B|Car_C) * P(Car_C))}{P(Open_B)}\n",
    "$$\n",
    "\n",
    "- $P(Open_B | Car_C)=1$\n",
    "- $P(Car_C) = \\frac{1}{3}$\n",
    "\n",
    "#### Marginal Probability\n",
    "\n",
    "$$\n",
    "P(Open_B) = P(Car_A) * P(Open_B | Car_A) + P(Car_B) * P(Open_B | Car_B) + P(Car_C) * P(Open_B | Car_C) \\\\\n",
    "= \\frac {1}{3} * \\frac {1}{2} + \\frac {1}{3} * 0 + \\frac {1}{3} * 1 \\\\\n",
    "= \\frac {1}{6} + \\frac {1}{3} \\\\\n",
    "= \\frac {1}{2}\n",
    "$$\n",
    "\n",
    "Lets Plug in the marginal probability to our original problem\n",
    "\n",
    "$P(Car_C| Open_B) = \\frac{1 * \\frac{1}{3}}{\\frac{1}{2}} = \\frac{2}{3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Intelligence\n",
    "\n",
    "The true goal of intelligence is to be able to produce reasonable behavior while dealing with diffrent sources of complexity.\n",
    "\n",
    "But what is intelligence?\n",
    "\n",
    "An agents domain affects how we judge its level of intelligence.\n",
    "\n",
    "## Defining Intelligence\n",
    "\n",
    "We oftern tend to use the word intelligence to describe things that we dont know how to explain, once we can explain then, we just say that the're algorithms or formulas.  They're only intelligent if we can't explain then.\n",
    "\n",
    "This definition is problematic. It implies that anything we design can never be intelligent because we would know how it works.\n",
    "\n",
    "Intelligence should be defined withing the context of a task,it just turns out that humans are intelligent at doing alot of things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Agent, Enviroment and State\n",
    "\n",
    "- Agent: intelligence system or software itself\n",
    "- Enviroment:\n",
    "- State:\n",
    "- Goal State: result the agent is trying to achive, it can be partial specification, but only include the final location\n",
    "    - It can be a set of different states that are all considered acceptable goals\n",
    "\n",
    "EXAMPLE: Roomba, An automated vacuum cleaner that moves around the house in consisten pattern sucking up dirt.\n",
    "\n",
    "- **ENVIROMENT**: room or  house its operating, but more specifically, teh floor, walls and all the objects that are on the floor tha tit may need ot avoid bumpin ginto.\n",
    "    - hardware components: sensors,motors\n",
    "\n",
    "- **AGENT**: from a Cartesian pov, you may only consider the software itself as the agent.\n",
    "    -At a higher level: the entire robot should be the agent., include all component that are directly accessable or controllable with some reliability.\n",
    "    \n",
    "- STATE: current position as well as all the different areas that it has already cleaned.\n",
    "    - We only repersent those items in the state that are necessary for completing the task.\n",
    "    \n",
    "- GOAL STATE: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Perception, Action and Cognition.\n",
    "\n",
    "- PERCEPTION: agent interacts with the enviroment by sensing its properties. By producing  usefull output or actions that fypically change the state of the enviroment.\n",
    "\n",
    "- COGNITION: The process which an agent decided what action to take based on its perceived inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Types of AI Problems\n",
    "\n",
    "### Enviroment states\n",
    "\n",
    "- Fully Observable\n",
    "    ex. Tic Tac Toe: you can see the entire board\n",
    "- Partially Observable\n",
    "    - ex Battleship, you can't see your opponents ship positions.\n",
    "    \n",
    "- Deterministic: know for sure the results of each action.\n",
    "- Stochastic: have uncertainty.\n",
    "\n",
    "- Discreate: finite number of states\n",
    "- Continous: possible states is infinite, tipically due to some properties that need to be stoes as real numbers.]\n",
    "\n",
    "- Benign: agent is the only on taking actions that intentionally affect its goal\n",
    "- Adversarial: more than one agents that can take actions to defeat its goal(found in competiative games)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Rational Behabior and Bounded Optimality\n",
    "\n",
    "Definitions:\n",
    "\n",
    "- **Intelligent agent**: one that takes actions to maximize its expected utility given a desired goal. commonly known as ***rational behavior***\n",
    "\n",
    "problem. It requirens agents to behave optimally yet its extreamly hard to find the optimal solution to may of the problems we are concerned with.\n",
    "\n",
    "We need to consither the constrains the agent is faced with. example: A partially observable enviroment, limited computational resources such as memory * processing speed. Rules imposed by the task at hand such as having to respond by a given deadline etc.\n",
    "\n",
    "Given these constrains, we can not expect an agent to always behave optimally, but we can come up with a levelof performace or **bound** that we desire the agent to meet.\n",
    "\n",
    "Ex: We want  a chess playing program to win 60% of the time against himan chess master\n",
    " \n",
    "- **Bounded Optimality**: Practical and feasible way of quantifying intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
